{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ce822a",
   "metadata": {},
   "source": [
    "**Loading Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e986405",
   "metadata": {},
   "source": [
    "**Loading Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80faaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Raw Datasets\n",
    "master = pd.read_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\master.csv\")\n",
    "transfer = pd.read_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\transfer.csv\")\n",
    "marketValue = pd.read_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\marketValuebefore.csv\")\n",
    "match = pd.read_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\matchfinal_fixed.csv\")\n",
    "lineup = pd.read_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\lineupfinal_fixed.csv\")\n",
    "team_value = pd.read_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\team_market_value.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb232a09",
   "metadata": {},
   "source": [
    "**Shape of Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da27cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculatin columns and rows for each dataframe\n",
    "master_rows, master_cols = master.shape\n",
    "transfer_rows, transfer_cols = transfer.shape\n",
    "marketValue_rows, marketValue_cols = marketValue.shape\n",
    "matchfinal_rows, matchfinal_cols = match.shape\n",
    "lineupfinal_rows, lineupfinal_cols = lineup.shape\n",
    "\n",
    "# Print the number of rows and columns for each dataframe\n",
    "print(f\"Masterdata Data Set: {master_rows} rows and {master_cols} columns\")\n",
    "print(f\"Transfer Data Set: {transfer_rows} rows and {transfer_cols} columns\")\n",
    "print(f\"Market Value Data Set: {marketValue_rows} rows and {marketValue_cols} columns\")\n",
    "print(f\"Match Final Data Set: {matchfinal_rows} rows and {matchfinal_cols} columns\")\n",
    "print(f\"Lineup Final Data Set: {lineupfinal_rows} rows and {lineupfinal_cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a749ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(master.head(3), headers='keys', tablefmt='pretty'))\n",
    "print(tabulate(transfer.head(3), headers='keys', tablefmt='pretty'))\n",
    "print(tabulate(marketValue.head(3), headers='keys', tablefmt='pretty'))\n",
    "print(tabulate(match.head(3), headers='keys', tablefmt='pretty'))\n",
    "print(tabulate(lineup.head(3), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066b361",
   "metadata": {},
   "source": [
    "**Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1fd85",
   "metadata": {},
   "source": [
    "Standardizing Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing Column Name for comeptition, season, playerid for every dataset\n",
    "master.rename(columns={'playerId': 'playerId'}, inplace=True)\n",
    "transfer.rename(columns={'playerId': 'playerId'}, inplace=True)\n",
    "marketValue.rename(columns={'playerId': 'playerId'}, inplace=True)\n",
    "lineup.rename(columns={'player_id': 'playerId'}, inplace=True)\n",
    "\n",
    "#MatchId\n",
    "match.rename(columns={'match_id': 'matchId'}, inplace=True)\n",
    "lineup.rename(columns={'match_id': 'matchId'}, inplace=True)\n",
    "\n",
    "#Competition Id\n",
    "lineup.rename(columns={'competition_id': 'competitionId'}, inplace=True)\n",
    "\n",
    "#Change name of austrian bundesliga\n",
    "transfer.loc[\n",
    "    (transfer['from_competition_competition_name'] == 'Bundesliga') & \n",
    "    (transfer['from_competition_competition_area'] == 'Austria'),\n",
    "    'from_competition_competition_name'\n",
    "] = 'Austrian Bundesliga'\n",
    "\n",
    "transfer.loc[\n",
    "    (transfer['to_competition_competition_name'] == 'Bundesliga') & \n",
    "    (transfer['to_competition_competition_area'] == 'Austria'),\n",
    "    'to_competition_competition_name'\n",
    "] = 'Austrian Bundesliga'\n",
    "\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910b794",
   "metadata": {},
   "source": [
    "Converting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, normalize the playerId across all dataframes by converting to int and then to str\n",
    "master['playerId'] = master['playerId'].astype(int)\n",
    "transfer['playerId'] = transfer['playerId'].astype(int)\n",
    "marketValue['playerId'] = marketValue['playerId'].astype(int)\n",
    "lineup['playerId'] = lineup['playerId'].astype(int)\n",
    "lineup['matchId'] = lineup['matchId'].astype(str)\n",
    "match['matchId'] = match['matchId'].astype(str)\n",
    "\n",
    "# Converting to Integer\n",
    "master['yearOfBirth'] = master['yearOfBirth'].astype('Int64')\n",
    "master['height'] = master['height'].astype('Int64')\n",
    "master['marketValue'] = master['marketValue'].astype('Int64')\n",
    "marketValue['marketvalue'] = marketValue['marketvalue'].astype('Int64')\n",
    "transfer['fee'] = transfer['fee'].astype('Int64')\n",
    "\n",
    "#Converting string\n",
    "lineup[\"competitionId\"] = lineup[\"competitionId\"].astype(str)\n",
    "\n",
    "#Converting string in Season\n",
    "lineup['season'] = lineup['season'].astype(str)\n",
    "transfer['season'] = transfer['season'].astype(str)\n",
    "match['season'] = match['season'].astype(str)\n",
    "team_value['season_id'] = team_value['season_id'].astype(str)  # Ensure season_id is string for merging\n",
    "\n",
    "\n",
    "# Convert 'scoreHome' and 'scoreAway' columns to numeric values;\n",
    "# if conversion fails (e.g., due to non-numeric strings), replace with NaN\n",
    "match['scoreHome'] = pd.to_numeric(match['scoreHome'], errors='coerce')\n",
    "match['scoreAway'] = pd.to_numeric(match['scoreAway'], errors='coerce')\n",
    "\n",
    "# then change it into 'Int64'\n",
    "match['scoreHome'] = match['scoreHome'].astype('Int64')\n",
    "match['scoreAway'] = match['scoreAway'].astype('Int64')\n",
    "lineup['home_team'] = lineup['home_team'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6a17f",
   "metadata": {},
   "source": [
    "Checking Unique PlayerIds in Transfer, Master, LineUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking Unique PlayerIds \n",
    "print(\"playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "print(\"playerIds in master:\", master['playerId'].nunique())\n",
    "print(\"playerIds in lineup:\", lineup['playerId'].nunique())\n",
    "\n",
    "# checking itnersection of playerIds\n",
    "transfer_ids = set(transfer['playerId'])\n",
    "common_with_master = transfer_ids.intersection(set(master['playerId']))\n",
    "common_with_lineup = transfer_ids.intersection(set(lineup['playerId']))\n",
    "common_lineup_master = set(lineup['playerId']).intersection(set(master['playerId']))\n",
    "\n",
    "print(\"playerIds in transfer ∩ master:\", len(common_with_master))\n",
    "print(\"playerIds in transfer ∩ lineup:\", len(common_with_lineup))\n",
    "print(\"playerIds in lineup ∩ master:\", len(common_lineup_master))\n",
    "\n",
    "\n",
    "common_all = transfer_ids.intersection(set(master['playerId']), set(lineup['playerId']))\n",
    "print(\"playerIds in transfer ∩ master ∩ lineup:\", len(common_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8cc3f0",
   "metadata": {},
   "source": [
    "Dropping / Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab254c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of rows of match and lineup\n",
    "print(f\"Count of Rows in match before filtering: {len(match)}\")\n",
    "print(f\"Count of Rows in lineup before filtering: {len(lineup)}\")\n",
    "\n",
    "#Dropping columns\n",
    "transfer = transfer.drop(columns=['internalId', 'externalId', 'playerInternalId','feePounds'])\n",
    "master = master.drop(columns=['secondNationality', 'secondaryPosition2'])\t\n",
    "\n",
    "#perf = perf.drop(columns=['index'])\n",
    "match = match.drop(columns = ['updatedAt', 'round', 'deleted', 'version'])\n",
    "\n",
    "#dropping duplicates for lineup data when playerid and match id is same\n",
    "lineup = lineup.drop_duplicates(subset=['playerId', 'matchId'], keep='first')\n",
    "\n",
    "#dropping duplicates\n",
    "master = master.drop_duplicates(keep='last')\n",
    "\n",
    "#perf = perf.drop_duplicates(keep='last')\n",
    "transfer = transfer.drop_duplicates(keep='last')\n",
    "\n",
    "#injury = injury.drop_duplicates(keep='last')\n",
    "marketValue = marketValue.drop_duplicates(keep='last')\n",
    "\n",
    "#comp = comp.drop_duplicates(keep='last')\n",
    "match = match.drop_duplicates(subset =['matchId'], keep='first')\n",
    "\n",
    "## Merge First and Last Name into Full Name\n",
    "master['playerName'] = master['firstName'] + ' ' + master['lastName']\n",
    "master = master.drop(columns=['firstName', 'lastName'])\n",
    "\n",
    "# Reorder columns to put playerName right after playerID\n",
    "cols = master.columns.tolist()\n",
    "playerid_index = cols.index('playerId')\n",
    "cols.insert(playerid_index + 1, cols.pop(cols.index('playerName')))\n",
    "master = master[cols]\n",
    "\n",
    "#cols = perf.columns.tolist()\n",
    "playerid_index = cols.index('playerId')\n",
    "cols.insert(playerid_index + 1, cols.pop(cols.index('playerName')))\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")\n",
    "\n",
    "## Add transferage\n",
    "# Merge transfer dataset with masterdata to match playerId\n",
    "merged_transfer = pd.merge(transfer, master[['playerId', 'height', 'mainPosition', 'positionGroup', 'foot', 'dateOfBirth', 'nationality']], on='playerId', how='left')\n",
    "\n",
    "# Calculate the transfer age: difference between transfer date and dateOfBirth\n",
    "merged_transfer['transferAge'] = pd.to_datetime(merged_transfer['date']).dt.year - pd.to_datetime(merged_transfer['dateOfBirth']).dt.year\n",
    "\n",
    "# If needed, drop the 'dateOfBirth' column after the calculation\n",
    "merged_transfer = merged_transfer.drop(columns=['dateOfBirth'])\n",
    "\n",
    "# If you want to update the original 'transfer' DataFrame\n",
    "transfer = merged_transfer\n",
    "transfer['transferAge'] = transfer['transferAge'].astype('Int64')\n",
    "\n",
    "## Reorder columns \n",
    "# Get current list of columns\n",
    "cols = transfer.columns.tolist()\n",
    "\n",
    "# Find the index of the 'season' column\n",
    "season_index = cols.index('playerName')\n",
    "\n",
    "# Remove 'transferAge' from the list\n",
    "cols.remove('transferAge')\n",
    "\n",
    "# Insert them right after 'season'\n",
    "cols.insert(season_index + 1, 'transferAge')\n",
    "\n",
    "# Reorder the DataFrame\n",
    "transfer = transfer[cols]\n",
    "print(tabulate(transfer.head(20), headers='keys', tablefmt='pretty'))\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")\n",
    "\n",
    "# count of rows of match and lineup\n",
    "print(f\"Count of Rows in match after filtering: {len(match)}\")\n",
    "print(f\"Count of Rows in lineup after filtering: {len(lineup)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0cc68",
   "metadata": {},
   "source": [
    "Filtering transfer for selecting last transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering transfer for selecting last transfer because for multiple transfer or loans in one season\n",
    "# Convert the 'date' column to datetime format\n",
    "transfer['date'] = pd.to_datetime(transfer['date'])\n",
    "\n",
    "# Sort the dataframe by 'playerid' and 'date'\n",
    "transfer = transfer.sort_values(by=['playerId', 'date'])\n",
    "\n",
    "# Define a function to filter transfer within a 6-month window\n",
    "def filter_transfer(group):\n",
    "    filtered = []\n",
    "    for i in range(len(group)):\n",
    "        if i == len(group) - 1 or (group.iloc[i + 1]['date'] - group.iloc[i]['date']).days > 182:\n",
    "            filtered.append(group.iloc[i])\n",
    "    return pd.DataFrame(filtered)\n",
    "\n",
    "# Group by 'playerid' and apply the filtering function\n",
    "transfer = transfer.groupby('playerId', group_keys=False).apply(filter_transfer)\n",
    "transfer.head()\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976e925",
   "metadata": {},
   "source": [
    "Dropping extra Match Id in Match Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be45acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking uniqer entries of playerId\n",
    "print(\"Unique match_id values in lineup und match:\")\n",
    "print(lineup['matchId'].nunique())\n",
    "print(match['matchId'].nunique())\n",
    "\n",
    "# common entries in matchId\n",
    "common_matches = pd.merge(lineup, match, on='matchId', how='inner')\n",
    "print(\"Common entries in match_id:\")\n",
    "print(common_matches['matchId'].nunique())\n",
    "\n",
    "# Showing matchids of non common matches in dataset match\n",
    "non_common_matches = match[~match['matchId'].isin(common_matches['matchId'])]\n",
    "\n",
    "# Dropping non common matches Match Ids in dataset Match\n",
    "# Dropping U16 U17 Matches\n",
    "match = match[match['matchId'].isin(common_matches['matchId'])]\n",
    "print(\"Unique entries in match_id after dropping:\")\n",
    "print(match['matchId'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce970e1",
   "metadata": {},
   "source": [
    "**Performance Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad877c2b",
   "metadata": {},
   "source": [
    "Dropping Na Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e783bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of na valuex in transfe rdatset in competition_competition_end\n",
    "print(\"Anzahl der NaN-Werte in 'to_competition_competition_end_date':\", transfer['to_competition_competition_end_date'].isna().sum())\n",
    "\n",
    "# umber of na valuex in transfe rdatset in competition_competition_end groupebd by comeptition Id\n",
    "na_counts = transfer.groupby('to_competition')['to_competition_competition_end_date'].apply(lambda x: x.isna().sum())\n",
    "print(\"Anzahl der NaN-Werte in 'to_competition_competition_end_date' gruppiert nach 'to_competition':\")\n",
    "\n",
    "#print sorted by count\n",
    "na_counts = na_counts.sort_values(ascending=False)\n",
    "print(na_counts)\n",
    "\n",
    "#dropping Nas in ciompetition end date\n",
    "transfer = transfer.dropna(subset=['to_competition_competition_end_date'])\n",
    "\n",
    "# number of na values in transfer dataset in date\n",
    "print(\"Anzahl der NaN-Werte in 'date':\", transfer['date'].isna().sum())\n",
    "\n",
    "#dropping nan values in date\n",
    "transfer = transfer.dropna(subset=['date'])\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0809a",
   "metadata": {},
   "source": [
    "Adding Performance Data before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Add match date to lineup ===\n",
    "lineup = lineup.merge(match[['matchId', 'date']], on='matchId', how='left')\n",
    "lineup['date'] = pd.to_datetime(lineup['date']).dt.strftime('%Y-%m-%d')\n",
    "lineup['date'] = pd.to_datetime(lineup['date']).dt.tz_localize(None)\n",
    "\n",
    "# === Prepare transfer data ===\n",
    "transfer['to_competition_competition_end_date'] = pd.to_datetime(transfer['to_competition_competition_end_date'])\n",
    "transfer['to_competition_competition_end_date'] = transfer['to_competition_competition_end_date'].dt.strftime('%m-%d')\n",
    "transfer['date'] = pd.to_datetime(transfer['date']).dt.tz_localize(None)\n",
    "\n",
    "# === Calculate real end date based on transfer year ===\n",
    "def compute_end_date(row):\n",
    "    transfer_year = row['date'].year\n",
    "    end_date = pd.to_datetime(f\"{transfer_year}-{row['to_competition_competition_end_date']}\")\n",
    "    if end_date <= row['date']:\n",
    "        end_date = end_date.replace(year=transfer_year + 1)\n",
    "    return end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "transfer['to_competition_competition_end_date'] = transfer.apply(compute_end_date, axis=1)\n",
    "\n",
    "transfer['start_date'] = pd.to_datetime(transfer['date'])\n",
    "transfer['end_date'] = pd.to_datetime(transfer['to_competition_competition_end_date'])\n",
    "\n",
    "# === Filter valid lineups ===\n",
    "merged = lineup.merge(\n",
    "    transfer[['playerId', 'start_date', 'end_date']],\n",
    "    on='playerId',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "valid_rows = merged[\n",
    "    (merged['date'] >= merged['start_date']) &\n",
    "    (merged['date'] <= merged['end_date'])\n",
    "]\n",
    "\n",
    "# === Merge match scores only once ===\n",
    "valid_rows = valid_rows.merge(match[['matchId', 'scoreHome', 'scoreAway']], on='matchId', how='left')\n",
    "\n",
    "# === Clean sheet calculation ===\n",
    "def is_clean_sheet(row):\n",
    "    if row['home_team']:\n",
    "        return row['scoreAway'] == 0\n",
    "    else:\n",
    "        return row['scoreHome'] == 0\n",
    "\n",
    "valid_rows['minutesPlayed'] = pd.to_numeric(valid_rows['minutesPlayed'], errors='coerce').fillna(0).astype(int)\n",
    "valid_rows['clean_sheet_raw'] = valid_rows.apply(is_clean_sheet, axis=1)\n",
    "valid_rows['clean_sheet_raw'] = valid_rows['clean_sheet_raw'].fillna(False).astype(bool)\n",
    "valid_rows['clean_sheet'] = valid_rows.apply(\n",
    "    lambda row: int(row['clean_sheet_raw'] and row['minutesPlayed'] >= 5),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Group by player/period and aggregate ===\n",
    "group_cols = ['playerId', 'start_date', 'end_date']\n",
    "minutes_summary = (\n",
    "    valid_rows\n",
    "    .groupby(group_cols)\n",
    "    .agg(\n",
    "        total_minutes_played=('minutesPlayed', 'sum'),\n",
    "        total_games=('date', 'count'),\n",
    "        goals_scored=('goals', 'sum'),\n",
    "        assists=('assists', 'sum'),\n",
    "        clean_sheets=('clean_sheet', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "minutes_summary['total_possible_minutes'] = minutes_summary['total_games'] * 90\n",
    "\n",
    "# === Merge aggregated stats back to transfer ===\n",
    "transfer = transfer.merge(minutes_summary, on=group_cols, how='left')\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")\n",
    "\n",
    "# === PREVIOUS SEASON PERFORMANCE ===\n",
    "\n",
    "transfer_prev = transfer.copy()\n",
    "transfer_prev['start_date'] = transfer_prev['start_date'] - pd.DateOffset(years=1)\n",
    "transfer_prev['end_date'] = transfer_prev['end_date'] - pd.DateOffset(years=1)\n",
    "\n",
    "merged_prev = lineup.merge(\n",
    "    transfer_prev[['playerId', 'start_date', 'end_date']],\n",
    "    on='playerId',\n",
    "    how='inner'\n",
    ")\n",
    "valid_rows_prev = merged_prev[\n",
    "    (merged_prev['date'] >= merged_prev['start_date']) &\n",
    "    (merged_prev['date'] <= merged_prev['end_date'])\n",
    "]\n",
    "\n",
    "# Merge scores once\n",
    "valid_rows_prev = valid_rows_prev.merge(match[['matchId', 'scoreHome', 'scoreAway']], on='matchId', how='left')\n",
    "\n",
    "valid_rows_prev['minutesPlayed'] = pd.to_numeric(valid_rows_prev['minutesPlayed'], errors='coerce').fillna(0).astype(int)\n",
    "valid_rows_prev['clean_sheet_raw'] = valid_rows_prev.apply(is_clean_sheet, axis=1)\n",
    "valid_rows_prev['clean_sheet_raw'] = valid_rows_prev['clean_sheet_raw'].fillna(False).astype(bool)\n",
    "valid_rows_prev['clean_sheet'] = valid_rows_prev.apply(\n",
    "    lambda row: int(row['clean_sheet_raw'] and row['minutesPlayed'] >= 5),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "minutes_summary_prev = (\n",
    "    valid_rows_prev\n",
    "    .groupby(['playerId', 'start_date', 'end_date'])\n",
    "    .agg(\n",
    "        prev_total_minutes_played=('minutesPlayed', 'sum'),\n",
    "        prev_total_games=('date', 'count'),\n",
    "        goals_scored_before=('goals', 'sum'),\n",
    "        assists_before=('assists', 'sum'),\n",
    "        clean_sheets_before=('clean_sheet', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "minutes_summary_prev['prev_total_possible_minutes'] = minutes_summary_prev['prev_total_games'] * 90\n",
    "\n",
    "transfer_prev = transfer_prev.merge(\n",
    "    minutes_summary_prev,\n",
    "    on=['playerId', 'start_date', 'end_date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "transfer_prev['start_date'] = transfer_prev['start_date'] + pd.DateOffset(years=1)\n",
    "transfer_prev['end_date'] = transfer_prev['end_date'] + pd.DateOffset(years=1)\n",
    "\n",
    "transfer = transfer.merge(\n",
    "    transfer_prev[['playerId', 'start_date', 'end_date',\n",
    "                   'prev_total_minutes_played', 'prev_total_games', 'prev_total_possible_minutes',\n",
    "                   'goals_scored_before', 'assists_before', 'clean_sheets_before']],\n",
    "    on=['playerId', 'start_date', 'end_date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Transfer data enriched with previous season\")\n",
    "print(transfer[['playerId', 'start_date', 'total_minutes_played', 'prev_total_minutes_played']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae816f0",
   "metadata": {},
   "source": [
    "Calculating percentage played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f240901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation for Percentage Played before and after\n",
    "transfer['percentage_played'] = (transfer['total_minutes_played'] / transfer['total_possible_minutes']) * 100\n",
    "transfer[\"percentage_played\"] = transfer[\"percentage_played\"].round(2)\n",
    "transfer['percentage_played_before'] = (transfer['prev_total_minutes_played'] / transfer['prev_total_possible_minutes']) * 100\n",
    "transfer[\"percentage_played_before\"] = transfer[\"percentage_played_before\"].round(2)\n",
    "\n",
    "# range of values for percentage played in league_perf\n",
    "print(\"Range of values for percentage played in league_perf:\")\n",
    "print(transfer[\"percentage_played\"].describe())\n",
    "\n",
    "# range of values for percentage played in league_perf\n",
    "print(\"Range of values for percentage played before in league_perf:\")\n",
    "print(transfer[\"percentage_played_before\"].describe())\n",
    "\n",
    "\n",
    "# plot of distribution of percentage played in transfer dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(transfer['percentage_played'], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Percentage Played in Transfer Dataset')\n",
    "plt.xlabel('Percentage Played')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(transfer['percentage_played_before'], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Percentage Played befpre in Transfer Dataset')\n",
    "plt.xlabel('Percentage Played')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35bb8c",
   "metadata": {},
   "source": [
    "Dropping unrealistic calculations of the league in malta and dropping transfer with multiple entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c916d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing rows with more than 100 percentage played\n",
    "print(\"Rows with more than 100 percentage played:\")\n",
    "nonsense = transfer[transfer[\"percentage_played\"] > 100]\n",
    "print(nonsense)\n",
    "\n",
    "# dropping unrealistic percentage played values\n",
    "transfer = transfer[(transfer[\"percentage_played\"] <= 100) | (transfer[\"percentage_played\"].isna())]\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")\n",
    "\n",
    "# counting how many players have same competitionId playerId and season\n",
    "transfer['count'] = transfer.groupby(['playerId', 'to_competition', 'season'])['playerId'].transform('count')\n",
    "\n",
    "#showing number\n",
    "print(transfer['count'].value_counts())\n",
    "\n",
    "#dropping values with count > 1\n",
    "transfer = transfer[transfer['count'] == 1]\n",
    "\n",
    "# Count of rows  in transfer after filtering\n",
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6dc5c",
   "metadata": {},
   "source": [
    "Adding closest marketvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if both date are same structure\n",
    "marketValue['date'] = pd.to_datetime(marketValue['date']).dt.tz_localize(None)\n",
    "transfer['date'] = pd.to_datetime(transfer['date']).dt.tz_localize(None)\n",
    "\n",
    "# Function to find the closest market value before the transfer date\n",
    "def find_closest_marketvalue(row):\n",
    "    player_id = row['playerId']\n",
    "    transfer_date = row['date']\n",
    "    \n",
    "    # Filter for matching player\n",
    "    matching = marketValue[marketValue['playerId'] == player_id]\n",
    "    \n",
    "    # Only keep dates before the transfer date\n",
    "    matching = matching[matching['date'] <= transfer_date]\n",
    "    \n",
    "    if matching.empty:\n",
    "        return None\n",
    "\n",
    "    # Calculate time delta (difference in days)\n",
    "    matching['timedelta'] = (transfer_date - matching['date'])\n",
    "    \n",
    "    # Get the row with the smallest timedelta\n",
    "    closest = matching.loc[matching['timedelta'].idxmin()]\n",
    "    return closest['marketvalue']\n",
    "\n",
    "# Apply the function to each transfer row\n",
    "transfer['marketvalue_closest'] = transfer.apply(find_closest_marketvalue, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5abc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique playerIds in transfer:\", transfer['playerId'].nunique())\n",
    "# Count of rows  in transfer after filtering\n",
    "print(f\"Count of Rows in transfer after filtering: {len(transfer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e50d96",
   "metadata": {},
   "source": [
    "Adding Market Value of Team/League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a410a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only unique and valid entries per team and season\n",
    "team_value = team_value.drop_duplicates(subset=['externalId', 'season_id'], keep='last')\n",
    "\n",
    "# Calculate the smallest valid market value (> 0)\n",
    "min_mv = team_value.loc[team_value['marketValue'] > 0, 'marketValue'].min()\n",
    "\n",
    "# Replace 0 market values with the smallest valid market value\n",
    "team_value['marketValue'] = team_value['marketValue'].replace(0, min_mv)\n",
    "\n",
    "# Ensure season columns are integers\n",
    "team_value['season_id'] = team_value['season_id'].astype(int)\n",
    "transfer['season'] = transfer['season'].astype(int)\n",
    "\n",
    "# Fallback function to retrieve closest market value by season if exact match is missing\n",
    "def get_closest_market_value(team_id, season, df_teamval):\n",
    "    subset = df_teamval[df_teamval['externalId'] == team_id]\n",
    "    if subset.empty:\n",
    "        return None\n",
    "    subset = subset.copy()\n",
    "    subset['season_diff'] = (subset['season_id'] - season).abs()\n",
    "    return subset.sort_values('season_diff').iloc[0]['marketValue']\n",
    "\n",
    "# Copy of transfer data to avoid modifying the original with new columns\n",
    "transfer_result = transfer.copy()\n",
    "\n",
    "### FROM-TEAM MARKET VALUE\n",
    "# Temporary dataframe with only necessary columns for from team\n",
    "temp_from = team_value[['externalId', 'season_id', 'marketValue']].rename(columns={\n",
    "    'externalId': 'from_teamId',\n",
    "    'season_id': 'season',\n",
    "    'marketValue': 'fromTeam_marketValue'\n",
    "})\n",
    "\n",
    "# Merge transfer with from team market value\n",
    "transfer_result = transfer_result.merge(temp_from, on=['from_teamId', 'season'], how='left')\n",
    "\n",
    "# Fallback for missing from team market value\n",
    "transfer_result['fromTeam_marketValue'] = transfer_result.apply(\n",
    "    lambda row: row['fromTeam_marketValue'] if pd.notna(row['fromTeam_marketValue'])\n",
    "    else get_closest_market_value(row['from_teamId'], row['season'], team_value),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "### TO-TEAM MARKET VALUE\n",
    "# Temporary dataframe with only necessary columns for to team\n",
    "temp_to = team_value[['externalId', 'season_id', 'marketValue']].rename(columns={\n",
    "    'externalId': 'to_teamId',\n",
    "    'season_id': 'season',\n",
    "    'marketValue': 'toTeam_marketValue'\n",
    "})\n",
    "\n",
    "# Merge transfer with to team market value\n",
    "transfer_result = transfer_result.merge(temp_to, on=['to_teamId', 'season'], how='left')\n",
    "\n",
    "# Fallback for missing to team market value\n",
    "transfer_result['toTeam_marketValue'] = transfer_result.apply(\n",
    "    lambda row: row['toTeam_marketValue'] if pd.notna(row['toTeam_marketValue'])\n",
    "    else get_closest_market_value(row['to_teamId'], row['season'], team_value),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Final cleanup: keep only original columns + the two market value columns\n",
    "columns_to_keep = transfer.columns.tolist() + ['fromTeam_marketValue', 'toTeam_marketValue']\n",
    "transfer_result = transfer_result[columns_to_keep]\n",
    "\n",
    "# Assign final result back to transfer dataframe\n",
    "transfer = transfer_result\n",
    "\n",
    "### === Calculate ratio between team market values ===\n",
    "transfer['team_market_value_relation'] = (\n",
    "    transfer['toTeam_marketValue'] / transfer['fromTeam_marketValue']\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd36cc",
   "metadata": {},
   "source": [
    "Adding Goals, assist, clean sheet, scorers and binary threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying for \n",
    "final_dataset = transfer.copy()\n",
    "\n",
    "#Adding binary threshold for percentage played when bigger equal to 50\n",
    "final_dataset['success'] = final_dataset['percentage_played'].apply(lambda x: 1 if x >= 50 else 0) \n",
    "\n",
    "#Adding binary threshold for percentage played when bigger equal to 50\n",
    "final_dataset['success_before'] = final_dataset['percentage_played_before'].apply(lambda x: 1 if x >= 50 else 0)          \n",
    "\n",
    "#sort final dataset by playerId, season, competitionId\n",
    "final_dataset = final_dataset.sort_values(by=['playerId', 'season'])\n",
    "\n",
    "# === Feature: scorer_before (before transfer) ===\n",
    "# Total of goals and assists before the transfer\n",
    "final_dataset[\"scorer_before\"] = final_dataset[\"goals_scored_before\"] + final_dataset[\"assists_before\"]\n",
    "\n",
    "#count rows and columns of final dataset\n",
    "final_dataset_rows, final_dataset_cols = final_dataset.shape\n",
    "print(f\"Final Data Set: {final_dataset_rows} rows and {final_dataset_cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5b65a",
   "metadata": {},
   "source": [
    "Adding fee to value ratio, foreign transfers, value age product and value per age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Feature 1: fee_to_value_ratio ===\n",
    "# Calculate only when both fee and market value are valid (not NaN and not zero)\n",
    "fee = final_dataset[\"fee\"]\n",
    "marketvalue = final_dataset[\"marketvalue_closest\"]\n",
    "\n",
    "# Initialize result array with NaNs\n",
    "fee_to_value_ratio = np.full(len(final_dataset), np.nan)\n",
    "\n",
    "# Define a mask for valid rows\n",
    "mask = (\n",
    "    fee.notna() &\n",
    "    marketvalue.notna() &\n",
    "    (fee != 0) &\n",
    "    (marketvalue != 0)\n",
    ")\n",
    "\n",
    "# Compute the ratio only for valid entries\n",
    "fee_to_value_ratio[mask] = fee[mask].values / marketvalue[mask].values\n",
    "\n",
    "# Assign the result to the dataframe\n",
    "final_dataset[\"fee_to_value_ratio\"] = fee_to_value_ratio\n",
    "\n",
    "# === Feature: foreign_transfer ===\n",
    "# Set to 1 if player moved to a country different from the previous league AND it's not the player's nationality\n",
    "final_dataset[\"foreign_transfer\"] = np.where(\n",
    "    (final_dataset[\"from_competition_competition_area\"] != final_dataset[\"to_competition_competition_area\"]) & \n",
    "    (final_dataset[\"to_competition_competition_area\"] != final_dataset[\"nationality\"]),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "# value age product\n",
    "final_dataset['value_age_product'] = final_dataset['marketvalue_closest'] * final_dataset['transferAge']\n",
    "\n",
    "# value per age\n",
    "final_dataset['value_per_age'] = final_dataset['marketvalue_closest'] / final_dataset['transferAge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2260cb",
   "metadata": {},
   "source": [
    "Adding Joker Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero percentage_played to avoid division by zero\n",
    "final_dataset['percentage_played_before'] = final_dataset['percentage_played_before'].replace(0, 0.000001)\n",
    "\n",
    "# Compute joker_ratio (goals per % played)\n",
    "final_dataset['joker_ratio'] = final_dataset['goals_scored_before'] / final_dataset['percentage_played_before']\n",
    "\n",
    "# Set joker_ratio and was_joker to NaN if percentage_played_before is NaN\n",
    "mask_na = final_dataset['percentage_played_before'].isna()\n",
    "final_dataset.loc[mask_na, ['joker_ratio', 'was_joker']] = np.nan\n",
    "\n",
    "# Threshold for being a joker: 90th percentile\n",
    "threshold = final_dataset['joker_ratio'].quantile(0.90)\n",
    "\n",
    "# Flag joker players (only if percentage_played_before is not NaN)\n",
    "final_dataset['was_joker'] = (\n",
    "    (final_dataset['joker_ratio'] > threshold) & \n",
    "    (final_dataset['percentage_played_before'] < 50)\n",
    ")\n",
    "\n",
    "# Optional: overwrite again to enforce NaNs for invalid rows (after flagging)\n",
    "final_dataset.loc[mask_na, ['joker_ratio', 'was_joker']] = np.nan\n",
    "\n",
    "# Sort and display top joker players\n",
    "joker_players = final_dataset[final_dataset['was_joker'].fillna(False)].sort_values(by='joker_ratio', ascending=False)\n",
    "\n",
    "# Columns to show\n",
    "cols_to_show = ['playerName', 'goals_scored_before', 'percentage_played_before', 'joker_ratio', 'was_joker']\n",
    "print(tabulate(joker_players[cols_to_show].head(10), headers='keys', tablefmt='fancy_grid', floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c6899",
   "metadata": {},
   "source": [
    "Grouping scorer, clean sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_sheets grouped with bins (0-2, 2-5, 5-10, 10-15, 15-20, 20+)\n",
    "bins_clean_sheets = [0, 2, 5, 10, 15, np.inf]\n",
    "labels_clean_sheets = ['0-1', '2-4', '5-9', '10-14', '15+']\n",
    "final_dataset['clean_sheets_before_grouped'] = pd.cut(final_dataset['clean_sheets_before'], bins=bins_clean_sheets, labels=labels_clean_sheets, right=False)\n",
    "\n",
    "# Grouping Scorers without defenders and goalkeepers \n",
    "def bin_scorer(row):\n",
    "    scorer = row[\"scorer_before\"]\n",
    "    position = str(row[\"mainPosition\"]).lower()\n",
    "\n",
    "    if pd.isna(scorer):\n",
    "        return np.nan  # wichtig: NaN beibehalten\n",
    "\n",
    "    if \"goalkeeper\" in position or \"defender\" in position:\n",
    "        return \"defender/goalkeeper\"\n",
    "    else:\n",
    "        if scorer <= 3:\n",
    "            return \"0-3\"\n",
    "        elif scorer <= 6:\n",
    "            return \"4-6\"\n",
    "        elif scorer <= 10:\n",
    "            return \"7-10\"\n",
    "        elif scorer <= 15:\n",
    "            return \"11-15\"\n",
    "        elif scorer <= 20:\n",
    "            return \"16-20\"\n",
    "        elif scorer <= 30:\n",
    "            return \"21-30\"\n",
    "        else:\n",
    "            return \"30+\"\n",
    "\n",
    "final_dataset[\"scorer_before_grouped_category\"] = final_dataset.apply(bin_scorer, axis=1)\n",
    "\n",
    "final_dataset[\"scorer_before_grouped_category\"] = pd.Categorical(\n",
    "    final_dataset[\"scorer_before_grouped_category\"],\n",
    "    categories=[\n",
    "        \"defender/goalkeeper\", \"0-3\", \"4-6\", \"7-10\", \"11-15\",\n",
    "        \"16-20\", \"21-30\", \"30+\"\n",
    "    ],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# scorer only for midfielder and attackers\n",
    "# Kopiere scorer_before in neue Spalte\n",
    "final_dataset[\"scorer_before_new\"] = final_dataset[\"scorer_before\"]\n",
    "\n",
    "# Wenn position goalkeeper oder defender → scorer = 0, aber nur falls scorer vorher nicht NaN war\n",
    "mask = final_dataset[\"positionGroup\"].str.lower().str.contains(\"goalkeeper|defender\", na=False) \n",
    "\n",
    "final_dataset.loc[mask, \"scorer_before_new\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525b2ff",
   "metadata": {},
   "source": [
    "**Cleaning columns and reorder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [\n",
    "    # Player info\n",
    "    'playerId', 'playerName', 'height', 'mainPosition', 'positionGroup', 'foot', 'nationality',\n",
    "\n",
    "    # Transfer info\n",
    "    'date', 'season', 'transferAge','isLoan', 'wasLoan', 'fee', 'marketvalue_closest', 'fee_to_value_ratio', 'foreign_transfer', 'value_age_product', 'value_per_age',\n",
    "\n",
    "    # From team\n",
    "    'from_team', 'from_teamId', 'from_competition',\n",
    "    'from_competition_competition_name', 'from_competition_competition_area',\n",
    "    'from_competition_competition_age_category', 'from_competition_competition_level',\n",
    "    'from_competition_competition_association', 'fromTeam_marketValue',\n",
    "\n",
    "    # To team\n",
    "    'to_team', 'to_teamId', 'to_competition',\n",
    "    'to_competition_competition_name', 'to_competition_competition_area',\n",
    "    'to_competition_competition_age_category', 'to_competition_competition_level',\n",
    "    'to_competition_competition_association', 'toTeam_marketValue', 'team_market_value_relation',\n",
    "\n",
    "    # Playing time current season\n",
    "    'start_date', 'end_date', 'total_minutes_played', 'total_games', 'total_possible_minutes',\n",
    "    'percentage_played',\n",
    "\n",
    "    # Playing time previous season\n",
    "    'prev_total_minutes_played', 'prev_total_games', 'prev_total_possible_minutes',\n",
    "    'percentage_played_before', 'was_joker',\n",
    "\n",
    "    # Performance previous season\n",
    "    'goals_scored_before','assists_before', 'scorer_before', 'scorer_before_new', 'scorer_before_grouped_category', 'clean_sheets_before', 'clean_sheets_before_grouped',\n",
    "\n",
    "    # Success metrics\n",
    "    'success', 'success_before'\n",
    "]\n",
    "final_dataset = final_dataset[new_order]\n",
    "\n",
    "final_dataset_rows, final_dataset_cols = final_dataset.shape\n",
    "print(f\"Final Data Set: {final_dataset_rows} rows and {final_dataset_cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458dd72",
   "metadata": {},
   "source": [
    "Dropping NAs in Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc597fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Define the list of columns to check ----\n",
    "cols_to_check = [\n",
    "    # Current season performance\n",
    "    'total_minutes_played', 'total_games', 'total_possible_minutes',\n",
    "    'percentage_played',\n",
    "\n",
    "    # Previous season playing time\n",
    "    'prev_total_minutes_played', 'prev_total_games', 'prev_total_possible_minutes',\n",
    "    'percentage_played_before', 'was_joker',\n",
    "\n",
    "    # Previous season performance\n",
    "    'goals_scored_before', 'assists_before', 'scorer_before',\n",
    "    'scorer_before_new', 'scorer_before_grouped_category',\n",
    "    'clean_sheets_before', 'clean_sheets_before_grouped'\n",
    "]\n",
    "\n",
    "# ---- Drop rows where ALL of these columns are NaN ----\n",
    "before = len(final_dataset)  # or your DataFrame name\n",
    "final_dataset.dropna(subset=cols_to_check, how='all', inplace=True)\n",
    "after = len(final_dataset)\n",
    "\n",
    "print(f\"Rows dropped because all {len(cols_to_check)} columns were NaN: {before - after}\")\n",
    "print(f\"Remaining rows: {after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c5d82",
   "metadata": {},
   "source": [
    "**Saving Final Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"\\\\Users\\\\kevdr\\\\OneDrive\\\\Desktop\\\\Master\\\\Köln\\\\Business Analytics\\\\Capstone\\\\Data\\\\final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9339688",
   "metadata": {},
   "source": [
    "**Data Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Data/final_dataset.csv')\n",
    "\n",
    "# Important features to visualize\n",
    "important_features = [\n",
    "    'height', 'transferAge', 'isLoan', 'wasLoan', 'was_joker', 'foreign_transfer',\n",
    "    'percentage_played_before', 'percentage_played',\n",
    "    'scorer_before_grouped_category', 'clean_sheets_before_grouped',\n",
    "    'fromTeam_marketValue', 'toTeam_marketValue', 'marketvalue_closest',\n",
    "    'from_competition_competition_level', 'to_competition_competition_level',\n",
    "    'foot', 'mainPosition', 'positionGroup',\n",
    "    'from_competition_competition_area', 'to_competition_competition_area',\n",
    "    'value_per_age', 'value_age_product', 'team_market_value_relation'\n",
    "]\n",
    "\n",
    "# Features to apply log transformation for better distribution visualization\n",
    "log_transform_features = [\n",
    "    'fromTeam_marketValue', 'toTeam_marketValue', 'marketvalue_closest',\n",
    "    'value_per_age', 'value_age_product', 'team_market_value_relation'\n",
    "]\n",
    "\n",
    "# Binary features (0 or 1)\n",
    "binary_features = ['isLoan', 'wasLoan', 'was_joker', 'foreign_transfer']\n",
    "\n",
    "# Categorical features that are integers (levels 1-4)\n",
    "categorical_integer_features = ['from_competition_competition_level', 'to_competition_competition_level']\n",
    "\n",
    "# Categorical string-based features\n",
    "categorical_features = [\n",
    "    'foot', 'mainPosition', 'positionGroup',\n",
    "    'from_competition_competition_area', 'to_competition_competition_area',\n",
    "    'scorer_before_grouped_category', 'clean_sheets_before_grouped'\n",
    "]\n",
    "\n",
    "# Normalize competition areas: keep top 20, group rest into 'Other'\n",
    "for area_col in ['from_competition_competition_area', 'to_competition_competition_area']:\n",
    "    top20 = df[area_col].value_counts().nlargest(20).index\n",
    "    df[area_col] = df[area_col].apply(lambda x: x if x in top20 else \"Other\")\n",
    "\n",
    "# Keep only valid grouped categories for scorers (e.g. '0–3', '4–7', ...)\n",
    "df['scorer_before_grouped_category'] = df['scorer_before_grouped_category'].apply(\n",
    "    lambda x: x if pd.notnull(x) and str(x).strip()[0].isdigit() else np.nan\n",
    ")\n",
    "\n",
    "# Define numeric features not already in other groups\n",
    "numeric_features = [f for f in important_features if f not in (binary_features + log_transform_features + categorical_integer_features + categorical_features)]\n",
    "\n",
    "# Combine all feature groups for plotting\n",
    "features_to_plot = numeric_features + binary_features + categorical_integer_features + categorical_features + log_transform_features\n",
    "\n",
    "# Set up subplot grid layout (3 columns)\n",
    "cols = 3\n",
    "rows = int(np.ceil(len(features_to_plot) / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle(\"Distributions of Key Features\", fontsize=18)\n",
    "\n",
    "# Loop through each feature and create appropriate plot\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    ax = axes[i]\n",
    "    data = df[feature].dropna()\n",
    "\n",
    "    if feature in binary_features:\n",
    "        data.value_counts().sort_index().plot.bar(ax=ax, color='red', edgecolor='black')\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels([\"No (0)\", \"Yes (1)\"])\n",
    "\n",
    "    elif feature in categorical_integer_features:\n",
    "        value_counts = data.astype(int).value_counts().reindex([1, 2, 3, 4], fill_value=0)\n",
    "        value_counts.plot.bar(ax=ax, color='red', edgecolor='black')\n",
    "        ax.set_xticks([0, 1, 2, 3])\n",
    "        ax.set_xticklabels([\"1\", \"2\", \"3\", \"4\"])\n",
    "\n",
    "    elif feature == 'scorer_before_grouped_category':\n",
    "        data.value_counts().sort_index(\n",
    "            key=lambda x: x.str.extract(r'(\\d+)').astype(float).squeeze()\n",
    "        ).plot.bar(ax=ax, color='red', edgecolor='black')\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    elif feature == 'clean_sheets_before_grouped':\n",
    "        data.value_counts().sort_index(\n",
    "            key=lambda x: x.str.extract(r'(\\d+)').astype(float).squeeze()\n",
    "        ).plot.bar(ax=ax, color='red', edgecolor='black')\n",
    "        ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    elif feature in categorical_features:\n",
    "        data.value_counts().sort_values(ascending=False).plot.bar(ax=ax, color='red', edgecolor='black')\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    elif feature in log_transform_features:\n",
    "        data = data.replace(0, np.nan).dropna()\n",
    "        np.log10(data).plot.hist(ax=ax, bins=30, color='red', edgecolor='black')\n",
    "        ax.set_xlabel(f\"log10({feature}) [€]\")\n",
    "        ax.set_title(f\"Distribution of {feature} [log10]\")\n",
    "\n",
    "    else:\n",
    "        data.plot.hist(ax=ax, bins=30, color='red', edgecolor='black')\n",
    "\n",
    "    if feature not in log_transform_features:\n",
    "        ax.set_title(f\"Distribution of {feature}\")\n",
    "        ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Hide any unused axes if the number of features is not divisible by the number of columns\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
